{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Leagues json array to json multi lines file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dl.cfg']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS']['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS']['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = 'leagues/'\n",
    "dest_folder = 'backup/leagues/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "#s3_resource = boto3.resource('s3')\n",
    "bucket_name='capstonefootballbucket'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start transfer JSON array to JSON rows file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_key=backup/leagues/leagues.json\n"
     ]
    }
   ],
   "source": [
    "paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "response = paginator.paginate(Bucket=bucket_name,  Prefix=source_folder, Delimiter='/', PaginationConfig={\"PageSize\": 300})\n",
    "count = 0\n",
    "for page in response:\n",
    "    files = page.get(\"Contents\")\n",
    "    for file in files:\n",
    "        key = file['Key']\n",
    "        if key.endswith('/'):\n",
    "            continue\n",
    "        #print(f\"file path = {key}\")\n",
    "        #file_name = os.path.basename(key)\n",
    "        # read original JSON file\n",
    "        file_obj = s3_client.get_object(Bucket=bucket_name, Key=key)\n",
    "        file_content = file_obj[\"Body\"].read().decode('utf-8')\n",
    "        data = json.loads(file_content)\n",
    "        flattened_data = pd.DataFrame()    \n",
    "        for item in data:\n",
    "            # First, flatten the nested JSON objects using pd.json_normalize()\n",
    "            flattened_item_df = json_normalize(item, sep='_')\n",
    "            seasons_df = json_normalize(flattened_item_df['seasons'].values[0], sep='_')\n",
    "            # Add 'seasons.' prefix to the column names in seasons_df\n",
    "            seasons_df.columns = ['seasons_' + col for col in seasons_df.columns]\n",
    "            # Duplicate flattened_item_df to match the length of seasons_df\n",
    "            flattened_item_df = pd.concat([flattened_item_df]*len(seasons_df), ignore_index=True)\n",
    "            flattened_item_df.drop(columns=['seasons'], inplace=True)\n",
    "            # Concatenate the dataframes\n",
    "            flattened_item_df = pd.concat([flattened_item_df, seasons_df], axis=1)\n",
    "            flattened_data = flattened_data.append(flattened_item_df, ignore_index=True)\n",
    "\n",
    "        json_lines = flattened_data.to_json(orient='records', lines=True)\n",
    "    \n",
    "        #build target object path\n",
    "        target_key = key.replace(source_folder, dest_folder)\n",
    "        print(f\"target_key={target_key}\")\n",
    "        #move target object\n",
    "        s3_client.copy_object(Bucket=bucket_name, CopySource=f\"{bucket_name}/{key}\", Key=target_key)\n",
    "        #verify that the tartet object exists\n",
    "        waiter = s3_client.get_waiter('object_exists')\n",
    "        waiter.wait(Bucket=bucket_name, Key=target_key)\n",
    "        \n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=key)\n",
    "        \n",
    "        # write to new file to destination folder\n",
    "        s3_client.put_object(Bucket=bucket_name, Key=key, Body=json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
